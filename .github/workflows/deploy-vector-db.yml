name: Deploy Vector Database

# Trigger on documentation updates or manual dispatch
on:
  push:
    branches:
      - main
    paths:
      # Only trigger when documentation changes
      - 'docs/claude/**'
      - 'docs/reddit/*.md'
      - 'vector_search/**'
  workflow_dispatch:
    inputs:
      force_reindex:
        description: 'Force full re-indexing of all documents'
        required: false
        type: boolean
        default: false

# Minimal permissions - only read repository contents
permissions:
  contents: read

# Prevent concurrent deployments
concurrency:
  group: vector-db-deploy
  cancel-in-progress: false

jobs:
  deploy:
    name: Deploy Vector Search Service
    runs-on: self-hosted
    timeout-minutes: 30

    steps:
      # Step 1: Checkout the repository
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 2  # Need at least 2 commits to detect changes

      # Step 2: Detect if documentation files changed
      - name: Detect documentation changes
        id: detect-changes
        run: |
          # Check if docs changed in this push (compare with previous commit)
          if git diff --name-only HEAD~1 HEAD | grep -qE '^(docs/claude/|docs/reddit/.*\.md)'; then
            echo "docs_changed=true" >> $GITHUB_OUTPUT
            echo "ğŸ“š Documentation changes detected"
          else
            echo "docs_changed=false" >> $GITHUB_OUTPUT
            echo "â„¹ï¸  No documentation changes detected"
          fi

          # Check if vector_search code changed
          if git diff --name-only HEAD~1 HEAD | grep -qE '^vector_search/'; then
            echo "code_changed=true" >> $GITHUB_OUTPUT
            echo "ğŸ”§ Vector search code changes detected"
          else
            echo "code_changed=false" >> $GITHUB_OUTPUT
            echo "â„¹ï¸  No vector search code changes detected"
          fi

      # Step 3: Create .env file with API key
      - name: Configure environment variables
        working-directory: vector_search
        run: |
          echo "GOOGLE_API_KEY=${{ secrets.GOOGLE_API_KEY }}" > .env
          echo "âœ… Environment variables configured"

      # Step 4: Check if ChromaDB collection exists
      - name: Check if ChromaDB collection exists
        id: check-collection
        working-directory: vector_search
        run: |
          if [ -d "chroma_db" ] && [ -n "$(ls -A chroma_db 2>/dev/null)" ]; then
            echo "collection_exists=true" >> $GITHUB_OUTPUT
            echo "âœ… ChromaDB collection exists"
          else
            echo "collection_exists=false" >> $GITHUB_OUTPUT
            echo "âš ï¸  ChromaDB collection does not exist - will trigger indexing"
          fi

      # Step 5: Re-index documents (if docs changed, forced, or collection missing)
      - name: Re-index documentation
        working-directory: vector_search
        if: steps.detect-changes.outputs.docs_changed == 'true' || github.event.inputs.force_reindex == 'true' || steps.check-collection.outputs.collection_exists == 'false'
        run: |
          echo "ğŸ”„ Starting document indexing..."

          # Build the Docker image first
          docker compose build

          # Run indexing in container
          if [[ "${{ github.event.inputs.force_reindex }}" == "true" ]]; then
            echo "âš ï¸  Force re-index requested, resetting database..."
            docker compose run --rm vector-search-api python index_documents.py --reset
          else
            echo "ğŸ“ Incremental indexing (changed documents only)..."
            docker compose run --rm vector-search-api python index_documents.py
          fi

          echo "âœ… Indexing completed"

      # Step 6: Build and deploy Docker container
      - name: Deploy vector search service
        working-directory: vector_search
        run: |
          echo "ğŸ³ Building and deploying Docker container..."

          # Stop existing container if running
          docker compose down || true

          # Build new image (use --no-cache only on force reindex for faster builds)
          if [[ "${{ github.event.inputs.force_reindex }}" == "true" ]]; then
            docker compose build --no-cache
          else
            docker compose build
          fi

          # Start container in detached mode
          docker compose up -d

          echo "âœ… Container deployed"

      # Step 7: Wait for service to be healthy
      - name: Wait for service health check
        working-directory: vector_search
        run: |
          echo "â³ Waiting for service to be healthy..."

          # Wait up to 60 seconds for health check
          for i in {1..12}; do
            if curl -sf http://localhost:8000/health > /dev/null 2>&1; then
              echo "âœ… Service is healthy!"
              exit 0
            fi
            echo "Attempt $i/12: Service not ready yet..."
            sleep 5
          done

          echo "âŒ Service failed to become healthy"
          docker compose logs
          exit 1

      # Step 8: Verify deployment
      - name: Verify deployment
        working-directory: vector_search
        run: |
          echo "ğŸ” Verifying deployment..."

          # Get health status
          echo "Health Status:"
          curl -s http://localhost:8000/health | python -m json.tool

          # Get statistics
          echo -e "\nDatabase Statistics:"
          curl -s http://localhost:8000/stats | python -m json.tool

          echo "âœ… Deployment verified successfully"

      # Step 9: Display deployment summary
      - name: Deployment summary
        if: always()
        working-directory: vector_search
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“Š Deployment Summary"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "Documentation Changed: ${{ steps.detect-changes.outputs.docs_changed }}"
          echo "Code Changed: ${{ steps.detect-changes.outputs.code_changed }}"
          echo "Force Re-index: ${{ github.event.inputs.force_reindex || 'false' }}"
          echo "Collection Existed: ${{ steps.check-collection.outputs.collection_exists || 'unknown' }}"
          echo "Container Status:"
          docker compose ps
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# Configuration Notes:
#
# Required Setup:
# 1. Self-hosted runner must be configured with label 'self-hosted'
# 2. Runner must have Docker and Docker Compose installed
# 3. Add GitHub secret: GOOGLE_API_KEY (get from https://aistudio.google.com/apikey)
#
# Deployment Behavior:
# - Triggers automatically when docs change in docs/claude/** or docs/reddit/*.md
# - Can be manually triggered with optional force re-index
# - Only re-indexes when documentation actually changes (saves time and API calls)
# - Uses Docker for containerization (no bare metal installation)
# - Includes health checks to verify successful deployment
#
# Manual Deployment:
# 1. Go to Actions tab in GitHub
# 2. Select "Deploy Vector Database"
# 3. Click "Run workflow"
# 4. Optionally enable "Force full re-indexing"
#
# Monitoring:
# - Check container logs: docker compose -f vector_search/docker compose.yml logs -f
# - Check health: curl http://localhost:8000/health
# - Check stats: curl http://localhost:8000/stats
#
# Troubleshooting:
# - If deployment fails, check workflow logs in GitHub Actions
# - Verify GOOGLE_API_KEY is set correctly in GitHub secrets
# - Ensure self-hosted runner has network access to Google API
# - Check Docker container logs for application errors
